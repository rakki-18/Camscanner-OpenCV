{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# captures video from webcam\n",
    "cam = cv2.VideoCapture(0)\n",
    "while(1):\n",
    "    ret , frame = cam.read()\n",
    "    # displays the frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    # reading the key pressed\n",
    "    k = cv2.waitKey(10) & 0xFF\n",
    "    # if 's' is pressed, image is saved\n",
    "    if k == 115:\n",
    "        cv2.imwrite('pic.png',gray)\n",
    "        break\n",
    "     # if esc is pressed, webcam closes   \n",
    "    if k == 27:\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to cartoonise the image by applying filters\n",
    "def cartooning(img_rgb):\n",
    "    num_down = 2       # number of downsampling steps\n",
    "    num_bilateral = 7  # number of bilateral filtering steps\n",
    "    \n",
    "    # downsample image using Gaussian pyramid\n",
    "    img_color = img_rgb\n",
    "    for _ in range(num_down):\n",
    "        img_color = cv2.pyrDown(img_color)\n",
    "\n",
    "    # repeatedly apply small bilateral filter instead of applying one large filter\n",
    "    for _ in range(num_bilateral):\n",
    "        img_color = cv2.bilateralFilter(img_color, d=9,\n",
    "                                        sigmaColor=9,\n",
    "                                        sigmaSpace=7)\n",
    "\n",
    "    # upsample image to original size\n",
    "    for _ in range(num_down):\n",
    "        img_color = cv2.pyrUp(img_color)\n",
    "\n",
    "    # convert to grayscale and apply median blur\n",
    "    img_gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    img_blur = cv2.medianBlur(img_gray, 7)\n",
    "\n",
    "    # detect and enhance edges\n",
    "    def edge(block,const):\n",
    "        return cv2.adaptiveThreshold(img_blur, 255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,blockSize=block,C=const)\n",
    "\n",
    "   \n",
    "    img_edge1 = edge(15,3)\n",
    "    \n",
    "    # convert back to color, bit-AND with color image\n",
    "    img_edge1 = cv2.cvtColor(img_edge1, cv2.COLOR_GRAY2RGB)\n",
    "    img_cartoon1 = cv2.bitwise_and(img_color, img_edge1)\n",
    "\n",
    "    img_cartoon1 = cv2.resize(img_cartoon1,(400,650))\n",
    "    cv2.imshow('cartoon',img_cartoon1)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cornerDetection(img):\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # finding a min of 4 corners which are atleast 250 units apart\n",
    "    corners = cv2.goodFeaturesToTrack(gray,4,0.01,250)\n",
    "    corners = np.int0(corners)\n",
    "    # duplicating img because the detected corners will be shown in dst\n",
    "    dst = img\n",
    "    \n",
    "    # displaying the corner points found in the image\n",
    "    for i in corners:\n",
    "        x,y = i.ravel()\n",
    "        cv2.circle(dst, (x,y),3,255,-1)\n",
    "    plt.figure(figsize=(75,75))\n",
    "    plt.subplot(121),plt.imshow(dst)\n",
    "   \n",
    "    plt.show()\n",
    "    \n",
    "    # alternate method to find corners\n",
    "    \"\"\"\n",
    "    gray = np.float32(gray)\n",
    "    dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "    \n",
    "    #result is dilated for marking the corners, not important\n",
    "    dst = cv2.dilate(dst,None)\n",
    "\n",
    "    # Threshold for an optimal value, it may vary depending on the image.\n",
    "    img[dst>0.1*dst.max()]=[0,0,255]\n",
    "    plt.subplot(121),plt.imshow(img)\"\"\"\n",
    "   \n",
    "    return corners\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspectiveTransform(img,corners):\n",
    "    \n",
    "    \n",
    "    rows,cols,ch = img.shape\n",
    "    # points which have to be transformed i.e the corners\n",
    "    pts1 = np.float32(corners)\n",
    "    # points to which it has to be transformed\n",
    "    pts2 = np.float32([[0,300],[300,0],[0,0],[300,300]])\n",
    "    \n",
    "    # apllying Perspective transformation\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    dst = cv2.warpPerspective(img,M,(300,300))\n",
    "    plt.subplot(121),plt.imshow(img),plt.title('Input')\n",
    "    plt.subplot(122),plt.imshow(dst),plt.title('Output')\n",
    "    plt.show()\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiseRemoval(img):\n",
    "    \n",
    "    # removing the noise in the image\n",
    "    dst = cv2.fastNlMeansDenoisingColored(img,None,10,10,7,21)\n",
    "\n",
    "    plt.subplot(121),plt.imshow(img)\n",
    "    plt.subplot(122),plt.imshow(dst)\n",
    "    plt.show()\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalModel(img):\n",
    "    \n",
    "    \n",
    "    #perform corner detection\n",
    "    corners = cornerDetection(img)\n",
    "    # performing perspective transformation with corners as endpoints\n",
    "    final_img = perspectiveTransform(img,corners)\n",
    "    #removing the noise\n",
    "    final_img = noiseRemoval(final_img)\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reading the image that we captured from the webcam\n",
    "img=cv2.imread(\"pic.png\")\n",
    "# applying our whole model on the image\n",
    "finalModel(img)\n",
    "# cartoonising the image\n",
    "cartooning(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
